{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read & write video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frames per second :  30.0 FPS\n",
      "Frame count :  0.0\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    " \n",
    "# Create a video capture object, in this case we are reading the video from a file\n",
    "vid_capture = cv2.VideoCapture(0)\n",
    " \n",
    "if (vid_capture.isOpened() == False):\n",
    "  print(\"Error opening the video file\")\n",
    "# Read fps and frame count\n",
    "else:\n",
    "  # Get frame rate information\n",
    "  # You can replace 5 with CAP_PROP_FPS as well, they are enumerations\n",
    "  fps = vid_capture.get(5)\n",
    "  print('Frames per second : ', fps,'FPS')\n",
    " \n",
    "  # Get frame count\n",
    "  # You can replace 7 with CAP_PROP_FRAME_COUNT as well, they are enumerations\n",
    "  frame_count = vid_capture.get(0)\n",
    "  print('Frame count : ', frame_count)\n",
    " \n",
    "while(vid_capture.isOpened()):\n",
    "  # vid_capture.read() methods returns a tuple, first element is a bool \n",
    "  # and the second is frame\n",
    "  ret, frame = vid_capture.read()\n",
    "  if ret == True:\n",
    "    cv2.imshow('Frame',frame)\n",
    "    # 20 is in milliseconds, try to increase the value, say 50 and observe\n",
    "    key = cv2.waitKey(5)\n",
    "     \n",
    "    if key == ord('q'):\n",
    "      break\n",
    "  else:\n",
    "    break\n",
    " \n",
    "# Release the video capture object\n",
    "vid_capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "vid_capture = cv2.VideoCapture(r\"C:\\Users\\dell\\Videos\\mediapipe\\pexels_videos.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.10.0) :-1: error: (-5:Bad argument) in function 'imshow'\n> Overload resolution failed:\n>  - imshow() missing required argument 'winname' (pos 1)\n>  - imshow() missing required argument 'winname' (pos 1)\n>  - imshow() missing required argument 'winname' (pos 1)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m cv2\u001b[38;5;241m.\u001b[39mimshow()\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.10.0) :-1: error: (-5:Bad argument) in function 'imshow'\n> Overload resolution failed:\n>  - imshow() missing required argument 'winname' (pos 1)\n>  - imshow() missing required argument 'winname' (pos 1)\n>  - imshow() missing required argument 'winname' (pos 1)\n"
     ]
    }
   ],
   "source": [
    "cv2.imshow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.10.0) :-1: error: (-5:Bad argument) in function 'read'\n> Overload resolution failed:\n>  - image is not a numpy array, neither a scalar\n>  - Expected Ptr<cv::UMat> for argument 'image'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m cv2\u001b[38;5;241m.\u001b[39mimshow(vid_capture\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvid\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.10.0) :-1: error: (-5:Bad argument) in function 'read'\n> Overload resolution failed:\n>  - image is not a numpy array, neither a scalar\n>  - Expected Ptr<cv::UMat> for argument 'image'\n"
     ]
    }
   ],
   "source": [
    "cv2.imshow(vid_capture.read(\"vid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "< cv2.VideoCapture 000002977EAD1070>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vid_capture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame Rate :  30 frames per second\n",
      "Frame count :  300.0\n"
     ]
    }
   ],
   "source": [
    "if (vid_capture.isOpened() == False):\n",
    "  print(\"Error opening the video file\")\n",
    "else:\n",
    "  # Get frame rate information\n",
    " \n",
    "  fps = int(vid_capture.get(5))\n",
    "  print(\"Frame Rate : \",fps,\"frames per second\")  \n",
    " \n",
    "  # Get frame count\n",
    "  frame_count = vid_capture.get(7)\n",
    "  print(\"Frame count : \", frame_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "while(vid_capture.isOpened()):\n",
    "  # vCapture.read() methods returns a tuple, first element is a bool \n",
    "  # and the second is frame\n",
    " \n",
    "  ret, frame = vid_capture.read()\n",
    "  if ret == True:\n",
    "    cv2.imshow('Frame',frame)\n",
    "    k = cv2.waitKey(5)\n",
    "    # 113 is ASCII code for q key\n",
    "    if k == 113:\n",
    "      break\n",
    "  else:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Release the objects\n",
    "vid_capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's start with the Imports \n",
    "import cv2\n",
    "import numpy as np\n",
    " \n",
    "# Read the image using imread function\n",
    "image = cv2.imread(r\"C:\\Users\\dell\\OneDrive\\Pictures\\IMG_20230109_172248.jpg\")\n",
    "img=cv2.imshow('Original Image', image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "down_width = 300\n",
    "down_height = 200\n",
    "down_points = (down_width, down_height)\n",
    "resized_down = cv2.resize(image, down_points, interpolation= cv2.INTER_LINEAR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#resizing images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's start with the Imports \n",
    "import cv2\n",
    "import numpy as np\n",
    " \n",
    "# Read the image using imread function\n",
    "image = cv2.imread(r\"C:\\Users\\dell\\OneDrive\\Pictures\\IMG_20230109_172248.jpg\")\n",
    "cv2.imshow('Original Image', image)\n",
    " \n",
    "# let's downscale the image using new  width and height\n",
    "down_width = 300\n",
    "down_height = 200\n",
    "down_points = (down_width, down_height)\n",
    "resized_down = cv2.resize(image, down_points, interpolation= cv2.INTER_LINEAR)\n",
    " \n",
    "# let's upscale the image using new  width and height\n",
    "up_width = 600\n",
    "up_height = 400\n",
    "up_points = (up_width, up_height)\n",
    "resized_up = cv2.resize(image, up_points, interpolation= cv2.INTER_LINEAR)\n",
    " \n",
    "# Display images\n",
    "#cv2.imshow('Resized Down by defining height and width', resized_down)\n",
    "#cv2.waitKey()\n",
    "cv2.imshow('Resized Up image by defining height and width', resized_up)\n",
    "cv2.waitKey()\n",
    " \n",
    "#press any key to close the windows\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    " \n",
    "# Read the original image\n",
    "img = cv2.imread(r\"C:\\Users\\dell\\OneDrive\\Pictures\\IMG_20230109_172248.jpg\") \n",
    "# Display original image\n",
    "#cv2.imshow('Original', img)\n",
    "cv2.waitKey(0)\n",
    " \n",
    "# Convert to graycsale\n",
    "img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "# Blur the image for better edge detection\n",
    "img_blur = cv2.GaussianBlur(img_gray, (3,3), 0) \n",
    "#cv2.imshow(\"gray\",img_gray)\n",
    "cv2.imshow(\"blur\",img_blur)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Edge detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    " \n",
    "# Read the original image\n",
    "img = cv2.imread(r\"C:\\Users\\dell\\OneDrive\\Pictures\\IMG_20230109_172248.jpg\") \n",
    "# Display original image\n",
    "#cv2.imshow('Original', img)\n",
    "#cv2.waitKey(0)\n",
    " \n",
    "# Convert to graycsale\n",
    "img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "# Blur the image for better edge detection\n",
    "img_blur = cv2.GaussianBlur(img_gray, (3,3), 0) \n",
    " \n",
    "# Sobel Edge Detection\n",
    "sobelx = cv2.Sobel(src=img_blur, ddepth=cv2.CV_64F, dx=1, dy=0, ksize=5) # Sobel Edge Detection on the X axis\n",
    "sobely = cv2.Sobel(src=img_blur, ddepth=cv2.CV_64F, dx=0, dy=1, ksize=5) # Sobel Edge Detection on the Y axis\n",
    "sobelxy = cv2.Sobel(src=img_blur, ddepth=cv2.CV_64F, dx=1, dy=1, ksize=5) # Combined X and Y Sobel Edge Detection\n",
    "# Display Sobel Edge Detection Images\n",
    "#cv2.imshow('Sobel X', sobelx)\n",
    "#cv2.waitKey(0)\n",
    "#cv2.imshow('Sobel Y', sobely)\n",
    "#cv2.waitKey(0)\n",
    "#cv2.imshow('Sobel X Y using Sobel() function', sobelxy)\n",
    "#cv2.waitKey(0)\n",
    " \n",
    "# Canny Edge Detection\n",
    "edges = cv2.Canny(image=img_blur, threshold1=100, threshold2=200) # Canny Edge Detection\n",
    "# Display Canny Edge Detection Image\n",
    "cv2.imshow('Canny Edge Detection', edges)\n",
    "cv2.waitKey(0)\n",
    " \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[  0, 255,   0],\n",
       "        [  0, 255,   0],\n",
       "        [  0, 255,   0],\n",
       "        ...,\n",
       "        [  0, 255,   0],\n",
       "        [  0, 255,   0],\n",
       "        [  0, 255,   0]],\n",
       "\n",
       "       [[  0, 255,   0],\n",
       "        [  0, 255,   0],\n",
       "        [  0, 255,   0],\n",
       "        ...,\n",
       "        [  0, 255,   0],\n",
       "        [  0, 255,   0],\n",
       "        [  0, 255,   0]],\n",
       "\n",
       "       [[  0, 255,   0],\n",
       "        [  0, 255,   0],\n",
       "        [101, 252, 103],\n",
       "        ...,\n",
       "        [110, 255, 109],\n",
       "        [  0, 255,   0],\n",
       "        [  0, 255,   0]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[  0, 255,   0],\n",
       "        [  0, 255,   0],\n",
       "        [ 30, 171,  24],\n",
       "        ...,\n",
       "        [ 40, 167,  27],\n",
       "        [  0, 255,   0],\n",
       "        [  0, 255,   0]],\n",
       "\n",
       "       [[  0, 255,   0],\n",
       "        [  0, 255,   0],\n",
       "        [  0, 255,   0],\n",
       "        ...,\n",
       "        [  0, 255,   0],\n",
       "        [  0, 255,   0],\n",
       "        [  0, 255,   0]],\n",
       "\n",
       "       [[  0, 255,   0],\n",
       "        [  0, 255,   0],\n",
       "        [  0, 255,   0],\n",
       "        ...,\n",
       "        [  0, 255,   0],\n",
       "        [  0, 255,   0],\n",
       "        [  0, 255,   0]]], dtype=uint8)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    " \n",
    "# read the image\n",
    "image = cv2.imread(r\"C:\\Users\\dell\\OneDrive\\Pictures\\Saved Pictures\\image-visualizing-simple-example-of-contour-detection.jpg\")\n",
    " \n",
    "# B, G, R channel splitting\n",
    "blue, green, red = cv2.split(image)\n",
    " \n",
    "# detect contours using blue channel and without thresholding\n",
    "contours1, hierarchy1 = cv2.findContours(image=blue, mode=cv2.RETR_TREE, method=cv2.CHAIN_APPROX_NONE)\n",
    " \n",
    "# draw contours on the original image\n",
    "image_contour_blue = image.copy()\n",
    "cv2.drawContours(image=image_contour_blue, contours=contours1, contourIdx=-1, color=(0, 255, 0), thickness=2, lineType=cv2.LINE_AA)\n",
    "# see the results\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# detect contours using green channel and without thresholding\n",
    "contours2, hierarchy2 = cv2.findContours(image=green, mode=cv2.RETR_TREE, method=cv2.CHAIN_APPROX_NONE)\n",
    "# draw contours on the original image\n",
    "image_contour_green = image.copy()\n",
    "cv2.drawContours(image=image_contour_green, contours=contours2, contourIdx=-1, color=(0, 255, 0), thickness=2, lineType=cv2.LINE_AA)\n",
    "# see the results\n",
    "cv2.imshow('Contour detection using green channels only', image_contour_green)\n",
    "cv2.waitKey(0)\n",
    "cv2.imwrite('green_channel.jpg', image_contour_green)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    " \n",
    "# read the image\n",
    "image = cv2.imread(r'C:\\Users\\dell\\OneDrive\\Pictures\\Saved Pictures\\image-visualizing-simple-example-of-contour-detection.jpg')\n",
    " \n",
    "# B, G, R channel splitting\n",
    "blue, green, red = cv2.split(image)\n",
    " \n",
    "# detect contours using blue channel and without thresholding\n",
    "contours1, hierarchy1 = cv2.findContours(image=blue, mode=cv2.RETR_TREE, method=cv2.CHAIN_APPROX_NONE)\n",
    " \n",
    "# draw contours on the original image\n",
    "image_contour_blue = image.copy()\n",
    "cv2.drawContours(image=image_contour_blue, contours=contours1, contourIdx=-1, color=(0, 255, 0), thickness=2, lineType=cv2.LINE_AA)\n",
    "# see the results\n",
    "#cv2.imshow('Contour detection using blue channels only', image_contour_blue)\n",
    "#cv2.waitKey(0)\n",
    "#cv2.imwrite('blue_channel.jpg', image_contour_blue)\n",
    "#cv2.destroyAllWindows()\n",
    " \n",
    "# detect contours using green channel and without thresholding\n",
    "contours2, hierarchy2 = cv2.findContours(image=green, mode=cv2.RETR_TREE, method=cv2.CHAIN_APPROX_NONE)\n",
    "# draw contours on the original image\n",
    "image_contour_green = image.copy()\n",
    "cv2.drawContours(image=image_contour_green, contours=contours2, contourIdx=-1, color=(0, 255, 0), thickness=2, lineType=cv2.LINE_AA)\n",
    "# see the results\n",
    "cv2.imshow('Contour detection using green channels only', image_contour_green)\n",
    "cv2.waitKey(0)\n",
    "cv2.imwrite('green_channel.jpg', image_contour_green)\n",
    "cv2.destroyAllWindows()\n",
    " \n",
    "# detect contours using red channel and without thresholding\n",
    "contours3, hierarchy3 = cv2.findContours(image=red, mode=cv2.RETR_TREE, method=cv2.CHAIN_APPROX_NONE)\n",
    "# draw contours on the original image\n",
    "image_contour_red = image.copy()\n",
    "cv2.drawContours(image=image_contour_red, contours=contours3, contourIdx=-1, color=(0, 255, 0), thickness=2, lineType=cv2.LINE_AA)\n",
    "# see the results\n",
    "cv2.imshow('Contour detection using red channels only', image_contour_red)\n",
    "cv2.waitKey(0)\n",
    "cv2.imwrite('red_channel.jpg', image_contour_red)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
